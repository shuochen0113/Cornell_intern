* plan/next

[2021-02-18 Thu 18:00]

MainView and GUI are now working, though on a single thread with
all communication handled by main.rs just calling functions on the
two objects.

the NodeDrawSystem's fragment shader now writes the node ID of the
fragment to a separate buffer, which is read from by the main thread
to find the node that the cursor is on top of at each frame.

the system assumes that the node IDs are compact and start from 1, and
that nodes are sent to the GPU in node ID order, with the vertex
shader setting the pipeline's `node_id` variable by simply dividing
the vertex index by 2 and adding 1

this works as long as the input GFA satisfies those constraints, and
all vertices in the entire graph are used in the NodeDrawSystem
pipeline, but a more robust solution would be to use the value taken
from the fragment shader buffer as an index into a slice of NodeIds
corresponding to the vertices -- something to keep in mind once the
rendering system becomes more flexible

[2021-02-16 Tue 16:00]

redesigning the application structure:

main & the event_loop will hold the viewport dimensions, vulkan
instance & queue, and swapchain -- and maybe framebuffers for now,
but they will probably also get moved to a more modular system

main initializes five other systems (names subject to change):
- Universe
- MainView
- GUI
- GraphQuery
- InputHandler

Universe holds the 2D graph layout, and manages the force-directed
layout (and/or whatever other layout approaches we'll end up adding),
and it owns all layout-specific configuration

the Universe is filled either from a GFA + layout TSV, or from a
PackedGraph (via GraphQuery)


MainView handles the view offset & scale, and all rendering that has to do
with the 2D graph. it has a NodeDrawSystem, and is responsible for getting
the latest 2D graph layout from the Universe, and converting it into vertices.
it should also cache the vertices, and only upload new vertices to the GPU when
necessary.

it also renders the view to a buffer where nodes are colored with their IDs,
and other systems can query that buffer. not sure if node selection should be
handled here or in GUI.


GUI manages the egui-based graphical UI widgets. it takes care of
updating the egui state with events, beginning and ending each frame,
and uses the GuiDrawSystem to render the GUI to the screen.

the GUI will include things like node info tooltips on hover, more
informative info boxes on node selection, options/config for the other
systems (including changing keybinds), modals to load a GFA, export to
image/SVG, etc.


GraphQuery owns the PackedGraph that's currently loaded. other systems
can query the PackedGraph via this system -- GraphQuery should provide
an async layer for queries that take longer to run, and have a cache


InputHandler takes the raw winit events produced by the main
event_loop, maps them to commands/other inputs using the keybind map,
and sends them to the other systems.


communication between all the systems will primarily be done using
crossbeam's mpmc channels. i may end up using tokio or another async
runtime.


[2021-02-12 Fri 22:00]

added support for loading graph layouts from TSV files produced by odgi's layout
command;

fixed an issue that distorted the view & didn't change the viewable area
when the ratio of the window dimensions changed;

implemented mapping from screen (click) coordinates to world coordinates,
working for all view offsets and scales;

factored out the window dimensions from the View struct, as it didn't really
make sense for them to be known to the UI/animation logic -- and that had already
led to some problems (e.g. the distorted view above)

spent a bit of time trying to get egui working with vulkano, but there's
a bit left

basalt is another UI framework, build around vulkano as the backend:
https://crates.io/crates/basalt

however, it may be a bit too opinionated

for now I might just use vulkano_text to get some text rendering started:
https://crates.io/crates/vulkano_text

vulkano_text provides a trait for drawing text, and implements it on
vulkano's AutoCommandBufferBuilder

... vulkano_text is actually extremely simple, the entire library is
less than 300 lines long. I should probably just stick to egui --
it's probably easier to get working than I expect.

[2021-02-11 Thu 17:00]

It looks like drawing tons of fairly small triangles is something GPUs
hate doing, and instancing doesn't help with that

it may be worth thinking about rendering each spine as a single consecutive
rectangle (or at least much fewer rectangles, each containing many nodes),
and letting the fragment shader handle not rendering the space between nodes

[2021-02-11 Thu 16:30]

loading GFAs from file (into packedgraphs) and rendering them, one
spine per path, and it seems to be working pretty well, with a yeast
pangenome (500k nodes, 112 paths, total path length 2.1M) running at
what looks to be around 30-45FPS.

A smaller graph with more paths can be ridiculously slow, as each path
gets its own `draw` command and vertex & uniform buffers, so I'll need
to fix that somehow.

More generally, I need to design a better, a more robust and flexible,
rendering system/loop -- ideally one that can take advantage of
multiple threads. To do that, though, I definitely need to read up on
how Vulkan works.

I also need to move the physics simulation to another thread.

[2021-02-10 Wed 21:30]

GUI crates:

imgui seems to be okay, but maybe a bit clunky to use, and there's only a 3rd-party,
unstable, vulkano renderer

egui looks more flexible, and is 100% rust and backend-agnostic
https://crates.io/crates/egui

another option is conrod and conrod-vulkano
https://crates.io/crates/conrod_vulkano

[2021-02-09 Tue 20:30]

making progress, but there's an annoying thing where motion looks kinda "snappy";
like the length of segments isn't constant, changing by a pixel or two as a segment
moves across pixel borders

antialiasing only helped a little

I think the problem may have to do with the translation and/or projection matrix

replacing some dumb equations that always evaluate to zero with 0.0 may have helped
a little bit

reversing the order of the translation & scaling matrices in the projection matrix
may have helped? but probably not

scaling the x-translation by the ratio of width/height also may have helped

either way, at this point it's really not that bad

it also seems to depend on the update rate -- I definitely need to restructure the
way animation updates are applied, so it doesn't depend on any locks

[2021-02-08 Mon 21:00]

read a GFA, take the paths

construct a linear sequence of rects/nodes to be rendered from each path;
all nodes just 1 or 2 degree to start with


once that's working, break the graph down into linear components, lay
them out in that way, and then reconnect them & apply some kind of
force to lay out the parallel parts


after that i need to handle loops, and probably a whole lot more

* stuff

updated 02/03/21

- [ ] options system
  - [ ] start with color schemes and/or toggling rendering stages
  - [ ] define OptionsSet and related types/traits
  - [ ] (mostly) generic GUI for OptionsSets
  - [ ] centralized storage & distribution to systems
  - [ ] save and load options

- [-] configurable keybinds
  - [X] generic type mapping winit input events to system-specific inputs
  - [ ] automate codegen of `impl Default for SystemInputBindings<_system_input_>`
  - [ ] save and load custom keybinds to/from file
  - [ ] GUI for modifying keybinds in the app

- [ ] customizable colors
  - [ ] use textures as color schemes instead of hardcoded on node ID
  - [ ] store background color in App & add variant to AppMsg or
    AppConfigMsg for changing it
  - [ ] make selection outline color configurable (either by changing
    the mask color, or the fragment color in the edge filter)

- [ ] semantic overlays/visualizations (depends on part of custom colors)
  - [ ] define "Overlay" to track the color scheme & maybe predicate
  - [ ] store all overlays in App or MainView, with one texture per overlay
  - [ ] track activated overlay (maybe allow 1-3 or so active?)
  - [ ] pass activated/relevant overlays to shaders per-node as part of node bitflags
  - [ ] pass activated/relevant overlay textures to frag shader & index on node via bitflag
  - [ ] GUI for defining and toggling overlays

- [ ] interaction with PackedGraph
  - [ ] overlays defined using PackedGraph iterators that take
    callbacks returning some overlay-specific type per node/path/etc.
  - [ ] live/concurrent overlay updates via graph iterators using
    crossbeam channels

- [ ] post-processing effects (selection outlines)
  - [ ] make edge detection parameters configurable
  - [ ] make gaussian blur parameters configurable

- [ ] rendering system structure
  - [ ] encapsulate entire rendering system so it can run on a separate thread from event_loop
  - [ ] modularize/clean up shader code
  - [ ] dynamically configurable post-processing w/ any number of effect pipelines
  - [ ] runtime shader hot-reloading
  - [ ] triple buffering w/ one thread per framebuffer

- [ ] implement fast approximate anti-aliasing (FXAA)

- [ ] multithreading
  - [ ] use tokio or another async runtime?
  - [ ] run inputmanager, each system, and each system's input
    handler, on separate threads/tasks
  - [ ] parallel rendering (see rendering system above)


- [ ] export PNG
  - [ ] start with exporting a screenshot of the current view
  - [ ] then export a larger view of the graph, using a separate framebuffer

- [ ] render node sequences (needs a text renderer, maybe SDF-based)
- [ ] render links as lines between segments

- [ ] support moving nodes (both click & drag by user, and later, real-time layout algo)
- [ ] graph layout

- [X] improve mapping from mouse (screen) to world coordinates
- [X] separate color buffer & individual segment colors
- [X] GUI via egui
- [X] load & render paths -- each with separate color, maybe?
- [X] MVP matrix transform for scaling & translation
- [X] GFA segments w/ length based on seq length
- [X] render GFA segments
- [X] antialiasing

* user actions

** menu
- load GFA
- save layout
- export image/SVG

- filter visible nodes/spines/edges/etc.
  - hide filtered elements
  - highlight filtered elements

- remove nodes/spines/edges/etc. (would require selection first?)

- configure visual parameters
  - set node width & base length (does base length impact physics?)
  - set edge width
  - change node color scheme
  - change spine color scheme
  - change edge color scheme

- configure physics parameters
  - set anim/physics speed
  - set edge min/max length
  - set edge springiness and other parameters

- view and modify spine Fourier coefficients

** any, discrete
- reset view
- reset scale
- pause layout (keyboard)
- reset layout
- select all?
- goto selection?
- menu navigation


** any, continuous
- menu navigation

** mouse only
- mousewheel zoom (centered on cursor)
- click & drag pan
- click & drag pan, but wrt distance from click until released
- draw rectangle & zoom to it
- click to select element
- hover on element
- click & drag elements

** keyboard only
- pan (arrow keys)
- zoom?
- modifiers

*** keyboard modifiers
- pan view with mouse
- faster pan/zoom
- slower pan/zoom
- drag elements with mouse
- select additional elements
